{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a940dd58",
   "metadata": {},
   "source": [
    "# üìä Survey Correlation Analysis Notebook\n",
    "This notebook:\n",
    "- Cleans messy survey question columns (e.g., 'High-10', 'Low-1')\n",
    "- Automatically extracts numeric values\n",
    "- Calculates Pearson correlations and p-values\n",
    "- Visualizes the correlation matrix\n",
    "- Generates plain-English executive summaries\n",
    "\n",
    "**üí° Designed to be flexible for any numeric-question-based survey dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ed484",
   "metadata": {},
   "source": [
    "## üîÅ Step 1: Load Your Survey Data\n",
    "Replace the file path with your dataset. Supports Excel or CSV formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789af630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your data (replace the filename with your actual file)\n",
    "df = pd.read_excel(\"your_survey_file.xlsx\")  # or pd.read_csv(\"your_file.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33854389",
   "metadata": {},
   "source": [
    "## üìã Step 2: View and Select Columns to Clean\n",
    "This prints the list of columns so you can identify your survey questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227180fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã Column Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89cf785",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 3: Choose Which Columns to Clean\n",
    "Select columns containing 1‚Äì10 scale responses (with or without text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c05fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† OPTION A: Manually specify the columns you want to clean\n",
    "# These should be columns that contain survey question responses using a numeric scale (e.g., 1‚Äì10)\n",
    "# This is useful if your columns do not follow a consistent naming pattern like 'Q1', 'Q2', etc.\n",
    "# üëâ Simply type your column names in the list below, using the exact names from df.columns\n",
    "\n",
    "columns_to_clean = [\n",
    "    # Example: 'Q1', 'Q2', 'Satisfaction_Score', 'Ease_of_Use'\n",
    "    # Replace with your actual column names below\n",
    "]\n",
    "\n",
    "print(\"üßº Manually selected columns for cleaning:\")\n",
    "print(columns_to_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd3316",
   "metadata": {},
   "source": [
    "## üßº Step 4: Clean Textual Ratings Like 'High-10'\n",
    "This function extracts the numeric part of strings such as 'Low-1', 'High-9', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a9cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    if isinstance(val, str):\n",
    "        match = re.search(r'\\d+(\\.\\d+)?', val)\n",
    "        return float(match.group()) if match else np.nan\n",
    "    elif isinstance(val, (int, float)):\n",
    "        return val\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric(val):\n",
    "    # If the value is missing (NaN), return it as-is\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "\n",
    "    # If the value is a string (e.g., 'High-10'), extract the numeric portion using regex\n",
    "    if isinstance(val, str):\n",
    "        match = re.search(r'\\d+(\\.\\d+)?', val)  # This finds integer or decimal numbers\n",
    "        return float(match.group()) if match else np.nan  # Return the number if found\n",
    "\n",
    "    # If the value is already a number (int or float), return it as-is\n",
    "    elif isinstance(val, (int, float)):\n",
    "        return val\n",
    "\n",
    "    # For all other types (e.g., lists, dicts, booleans), return NaN\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92dce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_clean:\n",
    "    df[col] = df[col].apply(extract_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1664916",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 6: Optional - Keep Only Values Between 1 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67080847",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_to_clean:\n",
    "    df[col] = df[col].apply(lambda x: x if pd.notna(x) and 1 <= x <= 10 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56648f1",
   "metadata": {},
   "source": [
    "## üìà Step 7: Calculate Correlation and P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = pd.DataFrame(index=columns_to_clean, columns=columns_to_clean, dtype=float)\n",
    "p_value_matrix = pd.DataFrame(index=columns_to_clean, columns=columns_to_clean, dtype=float)\n",
    "\n",
    "for col1 in columns_to_clean:\n",
    "    for col2 in columns_to_clean:\n",
    "        if col1 == col2:\n",
    "            correlation_matrix.loc[col1, col2] = 1.0\n",
    "            p_value_matrix.loc[col1, col2] = 0.0\n",
    "        else:\n",
    "            x = df[col1]\n",
    "            y = df[col2]\n",
    "            valid = x.notna() & y.notna()\n",
    "            if valid.sum() > 2:\n",
    "                r, p = pearsonr(x[valid], y[valid])\n",
    "                correlation_matrix.loc[col1, col2] = r\n",
    "                p_value_matrix.loc[col1, col2] = p\n",
    "            else:\n",
    "                correlation_matrix.loc[col1, col2] = np.nan\n",
    "                p_value_matrix.loc[col1, col2] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cda68",
   "metadata": {},
   "source": [
    "## üìä Step 8: Visualize Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be4647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix.astype(float), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title(\"Correlation Matrix of Survey Questions\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4069823",
   "metadata": {},
   "source": [
    "## üì¢ Step 9: Generate Executive Summary of Significant Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = \"\"\n",
    "thresholds = [(0.7, \"strong\"), (0.4, \"moderate\"), (0.2, \"weak\")]\n",
    "\n",
    "for col in correlation_matrix.columns:\n",
    "    sentences = []\n",
    "    for other_col in correlation_matrix.columns:\n",
    "        if col != other_col:\n",
    "            corr = correlation_matrix.loc[col, other_col]\n",
    "            p_val = p_value_matrix.loc[col, other_col]\n",
    "            if pd.notna(corr) and abs(corr) >= 0.2 and p_val < 0.05:\n",
    "                strength = next((label for thresh, label in thresholds if abs(corr) >= thresh), \"very weak\")\n",
    "                direction = \"positive\" if corr > 0 else \"negative\"\n",
    "                sentence = f\"- {col} is {strength}ly and {direction}ly correlated with {other_col} (r = {corr:.2f}, p = {p_val:.3f})\"\n",
    "                sentences.append(sentence)\n",
    "    if sentences:\n",
    "        summary += f\"\\n### {col}:\\n\" + \"\\n\".join(sentences) + \"\\n\"\n",
    "\n",
    "# Save summary to file\n",
    "with open(\"correlation_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "print(\"‚úÖ Executive summary saved as: correlation_summary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d66424",
   "metadata": {},
   "source": [
    "## üíæ Step 10: Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"cleaned_survey_file.xlsx\", index=False)\n",
    "print(\"‚úÖ Cleaned data saved to: cleaned_survey_file.xlsx\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
